{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Context-Aware Conversational Agent\n",
    "\n",
    "#### Overview\n",
    "This guide walks through building a conversational agent that maintains context across interactions. Using a modern AI framework, we'll design an agent capable of engaging in natural, coherent dialogues.\n",
    "\n",
    "#### Motivation\n",
    "Many basic chatbots struggle to maintain context, resulting in disjointed, frustrating experiences for users. This tutorial addresses that challenge by creating an agent that remembers and references previous parts of the conversation, enhancing interaction quality.\n",
    "\n",
    "#### Key Components\n",
    "- **Language Model**: The AI core that generates responses.\n",
    "- **Prompt Template**: Defines the conversation structure.\n",
    "- **History Manager**: Handles conversation history and context.\n",
    "- **Message Store**: Saves messages for each session.\n",
    "\n",
    "#### Method Details\n",
    "\n",
    "1. **Setting Up the Environment**  \n",
    "   Start by configuring the required AI framework and securing access to a suitable language model. This setup forms the foundation of the conversational agent.\n",
    "\n",
    "2. **Creating the Chat History Store**  \n",
    "   Develop a system to manage multiple sessions, with each session linked to its unique message history.\n",
    "\n",
    "3. **Defining the Conversation Structure**  \n",
    "   Build a template that includes:\n",
    "   - A system message specifying the AI's role\n",
    "   - A placeholder for conversation history\n",
    "   - The user's input\n",
    "\n",
    "   This format guides the AI responses and maintains conversation consistency.\n",
    "\n",
    "4. **Building the Conversational Chain**  \n",
    "   Integrate the prompt template with the language model to create a foundational conversational chain. Add a history management component that seamlessly manages inserting and retrieving conversation history.\n",
    "\n",
    "5. **Interacting with the Agent**  \n",
    "   Invoke the agent using a user input and session identifier. The history manager retrieves the relevant conversation history, inserts it into the prompt, and stores new messages after each interaction.\n",
    "\n",
    "#### Conclusion\n",
    "This conversational agent design offers multiple benefits:\n",
    "- **Context Awareness**: Enables the agent to reference previous conversation parts, fostering natural interactions.\n",
    "- **Simplicity**: A modular structure keeps implementation clear and straightforward.\n",
    "- **Flexibility**: The conversation structure can be easily adjusted, or a new language model integrated.\n",
    "- **Scalability**: The session-based approach allows multiple independent conversations to be managed.\n",
    "\n",
    "With this framework, you can further enhance the agent by:\n",
    "- Utilizing advanced prompt engineering techniques\n",
    "- Integrating external knowledge sources\n",
    "- Adding domain-specific capabilities\n",
    "- Incorporating error handling and conversation repair\n",
    "\n",
    "By emphasizing context management, this approach significantly enhances traditional chatbot functionality, making way for more engaging and supportive AI-driven interactions.\n",
    "\n",
    "#### Conversational Agent Tutorial\n",
    "This notebook demonstrates how to create a simple context-aware conversational agent using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain_experimental openai python-dotenv langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv() ##load all the nevironment variables\n",
    "# I have done with my github token if you dont have access to github models you can setup your openai key\n",
    "token=os.environ['GITHUB_TOKEN']\n",
    "endpoint = 'https://models.inference.ai.azure.com'\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=endpoint,\n",
    "    openai_api_key=token,\n",
    "    model=\"gpt-4o-mini\",  # Replace with the specific model if required\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store = {}\n",
    "\n",
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "AI: Your previous message was: \"Hello! How are you?\"\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user_123\"\n",
    "\n",
    "\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"Hello! How are you?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response1.content)\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What was my previous message?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
